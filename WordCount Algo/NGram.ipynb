{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nlp libraries\n",
    "import string\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "import nltk, re, string, collections\n",
    "from nltk.util import ngrams # function for making ngrams\n",
    "\n",
    "# set nlp variables\n",
    "english_stops = stopwords.words('english')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Text file into list\n",
    "with open(\"/Users/shira/OneDrive/Desktop/ML/Case Study1/filteredtext.txt\", \"r\", encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create functioon to clean text , Lowercases, takes out punct and stopwords and short strings\n",
    "def cleanning_tokens(tokens):\n",
    "    return [token.lower() for token in tokens if (token not in string.punctuation) and \n",
    "                   (token.lower() not in english_stops) and len(token) > 2]\n",
    "\n",
    "#create function to Lemmatize like remove plurals(play, plays)- it will save- play\n",
    "def lemmatize(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean words\n",
    "clean = cleanning_tokens(tokens)\n",
    "#print(clean)\n",
    "lemmi = lemmatize(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count ngram freqeuencies \n",
    "def counting_ngrams(tokens,n):\n",
    "    n_grams_count = ngrams(tokens, n)\n",
    "    ngramFrequency = collections.Counter(n_grams_count)\n",
    "    ngramFrequency = ngramFrequency.most_common()\n",
    "    return ngram_freq\n",
    "\n",
    "#Convert it into dic\n",
    "def ngram_to_dict(ngramFrequency):\n",
    "    l = []\n",
    "    for t in ngramFrequency:\n",
    "        l.append((' '.join(t[0]),t[1]))\n",
    "    return dict(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count word and ngram frequency\n",
    "word_freq = counting_ngrams(lemmi, 1)\n",
    "bigram_freq = counting_ngrams(lemmi, 2)\n",
    "#trigram_freq = counting_ngrams(lemmi, 3)\n",
    "#ngramFrequency = bigram_freq + trigram_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to directory\n",
    "word_freq = ngram_to_dict(word_freq)\n",
    "bigram_freq = ngram_to_dict(bigram_freq)\n",
    "#trigram_freq = ngram_to_dict(trigram_freq)\n",
    "#ngramFrequency = ngram_to_dict(ngram_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take output into text format\n",
    "import sys\n",
    "sys.stdout = open('bigram_.txt','wt',encoding='utf-8')\n",
    "print(bigram_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert list into dataframe\n",
    "import pandas as pd\n",
    "\n",
    "dfObj = pd.DataFrame(list(bbigram_freq.items()),columns=['bigram_Words', 'count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe into csv file\n",
    "dfObj.to_csv(\"output.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
